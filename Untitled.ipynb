{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3e304d4-94bf-4f73-81bb-1d2721a254f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0556216-c12e-45e7-ad31-972e399f1136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7ebeb-7042-4ba9-b530-52fc1ab1c30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m183.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m149.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0e6fc9-98f4-44c4-a192-cf8dcbbc31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed85ccac-1001-41fc-9bef-89e63f013333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3041e50-e82c-489b-8895-f34cae3eb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELDNN(nn.Module):\n",
    "  def __init__(self, input_dim = 2000, output_dim = 3):\n",
    "    super(ELDNN, self).__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(input_dim, 1024)\n",
    "    self.fc2 = nn.Linear(1024, 512)\n",
    "    self.fc3 = nn.Linear(512 , 256)\n",
    "    self.fc4 = nn.Linear(256, 128)\n",
    "    self.fc5 = nn.Linear(128, 64)\n",
    "    self.fc6 = nn.Linear(64, 32)\n",
    "    self.fc7 = nn.Linear(32, 16)\n",
    "    self.output = nn.Linear(16, output_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.fc1(x))\n",
    "    out = F.relu(self.fc2(out))\n",
    "    out = F.relu(self.fc3(out))\n",
    "    out = F.relu(self.fc4(out))\n",
    "    out = F.relu(self.fc5(out))\n",
    "    out = F.relu(self.fc6(out))\n",
    "    out = F.relu(self.fc7(out))\n",
    "    out = self.output(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8e90751-43ea-4362-a446-7fa9964447e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg22081084</th>\n",
       "      <th>cg03797768</th>\n",
       "      <th>cg25152348</th>\n",
       "      <th>cg23959187</th>\n",
       "      <th>cg03909902</th>\n",
       "      <th>cg13003239</th>\n",
       "      <th>cg14047339</th>\n",
       "      <th>cg08206623</th>\n",
       "      <th>cg03705947</th>\n",
       "      <th>cg20913106</th>\n",
       "      <th>...</th>\n",
       "      <th>cg22250642</th>\n",
       "      <th>cg18316234</th>\n",
       "      <th>cg14094063</th>\n",
       "      <th>cg26481784</th>\n",
       "      <th>cg10456628</th>\n",
       "      <th>cg17891715</th>\n",
       "      <th>cg20591167</th>\n",
       "      <th>cg03989244</th>\n",
       "      <th>cg10967101</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067825</td>\n",
       "      <td>0.071673</td>\n",
       "      <td>0.236929</td>\n",
       "      <td>0.060644</td>\n",
       "      <td>0.154614</td>\n",
       "      <td>0.315984</td>\n",
       "      <td>0.230590</td>\n",
       "      <td>0.211888</td>\n",
       "      <td>0.060157</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009307</td>\n",
       "      <td>0.012043</td>\n",
       "      <td>0.025695</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>0.721952</td>\n",
       "      <td>0.161008</td>\n",
       "      <td>0.058833</td>\n",
       "      <td>0.075718</td>\n",
       "      <td>0.255447</td>\n",
       "      <td>0.005149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094796</td>\n",
       "      <td>0.086184</td>\n",
       "      <td>0.354904</td>\n",
       "      <td>0.082719</td>\n",
       "      <td>0.258086</td>\n",
       "      <td>0.433023</td>\n",
       "      <td>0.344706</td>\n",
       "      <td>0.349188</td>\n",
       "      <td>0.113012</td>\n",
       "      <td>0.089922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027351</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>0.034575</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.813831</td>\n",
       "      <td>0.190434</td>\n",
       "      <td>0.104741</td>\n",
       "      <td>0.054743</td>\n",
       "      <td>0.300870</td>\n",
       "      <td>0.011755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056855</td>\n",
       "      <td>0.079069</td>\n",
       "      <td>0.241682</td>\n",
       "      <td>0.047937</td>\n",
       "      <td>0.162030</td>\n",
       "      <td>0.313171</td>\n",
       "      <td>0.241502</td>\n",
       "      <td>0.209317</td>\n",
       "      <td>0.068280</td>\n",
       "      <td>0.040221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033237</td>\n",
       "      <td>0.017566</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>0.042251</td>\n",
       "      <td>0.716593</td>\n",
       "      <td>0.180039</td>\n",
       "      <td>0.074848</td>\n",
       "      <td>0.066050</td>\n",
       "      <td>0.291670</td>\n",
       "      <td>-0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.131301</td>\n",
       "      <td>0.147794</td>\n",
       "      <td>0.466630</td>\n",
       "      <td>0.110794</td>\n",
       "      <td>0.337466</td>\n",
       "      <td>0.520672</td>\n",
       "      <td>0.432830</td>\n",
       "      <td>0.467904</td>\n",
       "      <td>0.108296</td>\n",
       "      <td>0.118771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015423</td>\n",
       "      <td>0.022930</td>\n",
       "      <td>0.033469</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.863897</td>\n",
       "      <td>0.227519</td>\n",
       "      <td>0.089714</td>\n",
       "      <td>0.039197</td>\n",
       "      <td>0.340138</td>\n",
       "      <td>-0.010877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130379</td>\n",
       "      <td>0.112099</td>\n",
       "      <td>0.444738</td>\n",
       "      <td>0.090724</td>\n",
       "      <td>0.317733</td>\n",
       "      <td>0.488783</td>\n",
       "      <td>0.397166</td>\n",
       "      <td>0.437043</td>\n",
       "      <td>0.135125</td>\n",
       "      <td>0.110134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>0.033012</td>\n",
       "      <td>0.041466</td>\n",
       "      <td>0.840102</td>\n",
       "      <td>0.193905</td>\n",
       "      <td>0.098894</td>\n",
       "      <td>0.053489</td>\n",
       "      <td>0.322819</td>\n",
       "      <td>0.008213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.131040</td>\n",
       "      <td>0.145871</td>\n",
       "      <td>0.474681</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>0.322506</td>\n",
       "      <td>0.530088</td>\n",
       "      <td>0.413414</td>\n",
       "      <td>0.472793</td>\n",
       "      <td>0.138681</td>\n",
       "      <td>0.113618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>0.022587</td>\n",
       "      <td>0.048488</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.902313</td>\n",
       "      <td>0.199946</td>\n",
       "      <td>0.116739</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>0.308106</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.129130</td>\n",
       "      <td>0.137477</td>\n",
       "      <td>0.464111</td>\n",
       "      <td>0.117869</td>\n",
       "      <td>0.307346</td>\n",
       "      <td>0.513985</td>\n",
       "      <td>0.430763</td>\n",
       "      <td>0.457855</td>\n",
       "      <td>0.125519</td>\n",
       "      <td>0.118040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018568</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.033812</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.881516</td>\n",
       "      <td>0.180757</td>\n",
       "      <td>0.092142</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.308357</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.131299</td>\n",
       "      <td>0.132115</td>\n",
       "      <td>0.498803</td>\n",
       "      <td>0.100525</td>\n",
       "      <td>0.329762</td>\n",
       "      <td>0.513397</td>\n",
       "      <td>0.409796</td>\n",
       "      <td>0.454124</td>\n",
       "      <td>0.126254</td>\n",
       "      <td>0.098700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>0.044996</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.865289</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.104979</td>\n",
       "      <td>0.053346</td>\n",
       "      <td>0.325935</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.125473</td>\n",
       "      <td>0.126658</td>\n",
       "      <td>0.461756</td>\n",
       "      <td>0.114736</td>\n",
       "      <td>0.332860</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.411351</td>\n",
       "      <td>0.442717</td>\n",
       "      <td>0.123535</td>\n",
       "      <td>0.109764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020176</td>\n",
       "      <td>0.017518</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.021594</td>\n",
       "      <td>0.842266</td>\n",
       "      <td>0.173433</td>\n",
       "      <td>0.089850</td>\n",
       "      <td>0.053783</td>\n",
       "      <td>0.329780</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.121248</td>\n",
       "      <td>0.140879</td>\n",
       "      <td>0.443409</td>\n",
       "      <td>0.109199</td>\n",
       "      <td>0.292014</td>\n",
       "      <td>0.509937</td>\n",
       "      <td>0.391046</td>\n",
       "      <td>0.428991</td>\n",
       "      <td>0.115621</td>\n",
       "      <td>0.111969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020233</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.020254</td>\n",
       "      <td>0.868795</td>\n",
       "      <td>0.230420</td>\n",
       "      <td>0.093855</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>0.308252</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cg22081084  cg03797768  cg25152348  cg23959187  cg03909902  cg13003239  \\\n",
       "0     0.067825    0.071673    0.236929    0.060644    0.154614    0.315984   \n",
       "1     0.094796    0.086184    0.354904    0.082719    0.258086    0.433023   \n",
       "2     0.056855    0.079069    0.241682    0.047937    0.162030    0.313171   \n",
       "3     0.131301    0.147794    0.466630    0.110794    0.337466    0.520672   \n",
       "4     0.130379    0.112099    0.444738    0.090724    0.317733    0.488783   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "35    0.131040    0.145871    0.474681    0.114857    0.322506    0.530088   \n",
       "36    0.129130    0.137477    0.464111    0.117869    0.307346    0.513985   \n",
       "37    0.131299    0.132115    0.498803    0.100525    0.329762    0.513397   \n",
       "38    0.125473    0.126658    0.461756    0.114736    0.332860    0.495076   \n",
       "39    0.121248    0.140879    0.443409    0.109199    0.292014    0.509937   \n",
       "\n",
       "    cg14047339  cg08206623  cg03705947  cg20913106  ...  cg22250642  \\\n",
       "0     0.230590    0.211888    0.060157    0.040540  ...    0.009307   \n",
       "1     0.344706    0.349188    0.113012    0.089922  ...    0.027351   \n",
       "2     0.241502    0.209317    0.068280    0.040221  ...    0.033237   \n",
       "3     0.432830    0.467904    0.108296    0.118771  ...    0.015423   \n",
       "4     0.397166    0.437043    0.135125    0.110134  ...    0.004649   \n",
       "..         ...         ...         ...         ...  ...         ...   \n",
       "35    0.413414    0.472793    0.138681    0.113618  ...    0.019590   \n",
       "36    0.430763    0.457855    0.125519    0.118040  ...    0.018568   \n",
       "37    0.409796    0.454124    0.126254    0.098700  ...    0.018744   \n",
       "38    0.411351    0.442717    0.123535    0.109764  ...    0.020176   \n",
       "39    0.391046    0.428991    0.115621    0.111969  ...    0.020233   \n",
       "\n",
       "    cg18316234  cg14094063  cg26481784  cg10456628  cg17891715  cg20591167  \\\n",
       "0     0.012043    0.025695    0.027153    0.721952    0.161008    0.058833   \n",
       "1     0.009823    0.034575    0.037111    0.813831    0.190434    0.104741   \n",
       "2     0.017566    0.011917    0.042251    0.716593    0.180039    0.074848   \n",
       "3     0.022930    0.033469    0.019341    0.863897    0.227519    0.089714   \n",
       "4     0.015531    0.033012    0.041466    0.840102    0.193905    0.098894   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "35    0.022587    0.048488    0.025000    0.902313    0.199946    0.116739   \n",
       "36    0.022358    0.033812    0.020528    0.881516    0.180757    0.092142   \n",
       "37    0.021729    0.044996    0.023103    0.865289    0.210800    0.104979   \n",
       "38    0.017518    0.036842    0.021594    0.842266    0.173433    0.089850   \n",
       "39    0.016273    0.041533    0.020254    0.868795    0.230420    0.093855   \n",
       "\n",
       "    cg03989244  cg10967101     label  \n",
       "0     0.075718    0.255447  0.005149  \n",
       "1     0.054743    0.300870  0.011755  \n",
       "2     0.066050    0.291670 -0.001340  \n",
       "3     0.039197    0.340138 -0.010877  \n",
       "4     0.053489    0.322819  0.008213  \n",
       "..         ...         ...       ...  \n",
       "35    0.059448    0.308106  1.000000  \n",
       "36    0.042900    0.308357  1.000000  \n",
       "37    0.053346    0.325935  1.000000  \n",
       "38    0.053783    0.329780  1.000000  \n",
       "39    0.050749    0.308252  1.000000  \n",
       "\n",
       "[340 rows x 2001 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_aug = pd.read_csv(\"aug_CpGSample.csv\")\n",
    "df_real = pd.read_csv(\"CpGSitesWithLabel.csv\")\n",
    "\n",
    "df_aug = df_aug + np.random.normal(0, 0.01, size=df_aug.shape)\n",
    "\n",
    "# accuracy, precision, recall, r^2\n",
    "\n",
    "df = pd.concat([df_aug, df_real], axis = 0)\n",
    "df = df.drop(columns = \"Unnamed: 0\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98db9a38-1eb8-499a-8ec7-f91dc548fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X = df.iloc[:, :-1].values.astype('float32')\n",
    "y = df['label'].values.astype('int64')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 42)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5212a4a-ecb4-4014-93e5-63799eb1541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 4.4815, Train Accuracy: 75.00%\n",
      "Epoch 200, Loss: 3.9760, Train Accuracy: 68.75%\n",
      "Epoch 300, Loss: 4.6237, Train Accuracy: 75.00%\n",
      "Epoch 400, Loss: 2.8691, Train Accuracy: 87.50%\n",
      "Epoch 500, Loss: 3.2209, Train Accuracy: 81.25%\n",
      "Epoch 600, Loss: 2.1774, Train Accuracy: 81.25%\n",
      "Epoch 700, Loss: 1.9719, Train Accuracy: 87.50%\n",
      "Epoch 800, Loss: 1.9789, Train Accuracy: 87.50%\n",
      "Epoch 900, Loss: 1.9353, Train Accuracy: 87.50%\n",
      "Epoch 1000, Loss: 9.2283, Train Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "model = ELDNN().to(device)\n",
    "epochs = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  model.train()\n",
    "  total_loss = 0.0\n",
    "\n",
    "  for x_batch, y_batch in train_loader:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x_batch)\n",
    "    loss = criterion(outputs, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    predicted = torch.argmax(outputs, dim=1)\n",
    "    correct += (predicted == y_batch).sum().item()\n",
    "    total += y_batch.size(0)\n",
    "    \n",
    "  if (epoch+1) % 100 == 0:\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "929b05f1-672e-4119-a638-a30b1ddb7739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 4.0288, Train Acc: 70.221%, Test Acc: 69.118%\n",
      "Epoch 200, Loss: 4.0905, Train Acc: 70.588%, Test Acc: 66.176%\n",
      "Epoch 300, Loss: 3.0628, Train Acc: 89.338%, Test Acc: 66.176%\n",
      "Epoch 400, Loss: 3.2193, Train Acc: 82.721%, Test Acc: 69.118%\n",
      "Epoch 500, Loss: 0.4872, Train Acc: 99.632%, Test Acc: 61.765%\n",
      "Epoch 600, Loss: 0.0630, Train Acc: 100.000%, Test Acc: 66.176%\n",
      "Epoch 700, Loss: 0.0763, Train Acc: 100.000%, Test Acc: 61.765%\n",
      "Epoch 800, Loss: 0.0031, Train Acc: 100.000%, Test Acc: 66.176%\n",
      "Epoch 900, Loss: 0.0010, Train Acc: 100.000%, Test Acc: 66.176%\n",
      "Epoch 1000, Loss: 0.0004, Train Acc: 100.000%, Test Acc: 66.176%\n"
     ]
    }
   ],
   "source": [
    "model = ELDNN().to(device)\n",
    "epochs = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # ==== TRAINING ====\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "    train_accuracy = correct / total * 100\n",
    "\n",
    "    # ==== TEST EVALUATION ====\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        model.eval()\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in test_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                outputs = model(x_batch)\n",
    "                predicted = torch.argmax(outputs, dim=1)\n",
    "                test_correct += (predicted == y_batch).sum().item()\n",
    "                test_total += y_batch.size(0)\n",
    "\n",
    "        test_accuracy = test_correct / test_total * 100\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Train Acc: {train_accuracy:.3f}%, Test Acc: {test_accuracy:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236934c6-3d64-4fad-84e1-f63b685a5462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
